---
title: "Tutorial rápido - Primeira busca de registros de ocorrência de plantas vasculares no Parque Estadual Serra do Mar, São Paulo"
author: "Matheus Colli-Silva"
date: "09/03/2022"
output: html_document
---

## 1. Introdução


Neste tutorial, você deverá encontrar informações sobre:


1) Como realizar buscas no GBIF (The Global Biodiversity Information Facility) para registros de ocorrência;


2) Como fazer as buscas para uma área (gazzetteer) de interesse, utilizando SQL;


3) Como discriminar registros mais ou menos confiáveis, considerando a origem do registro, bem como suas informações taxonômicas e geográficas;


4) Como obter uma tabela com registros preliminares para posterior checagem manual.

Note que este tutorial é preliminar e apenas organiza um procedimento que deve ainda ser incrementado.


## 2. Preparando o terreno: o que você vai precisar


Este tutorial trabalha com a [linguagem R](https://www.r-project.org/). Também é recomendado que você instale o [RStudio](https://www.rstudio.com/), um ambiente de desenvolvimento integrado à linguagem R que pode facilitar o trabalho de programação. 

Você também vai precisar de alguns documentos de antemão para executar as buscas.


### 2.1. Dataset de registros do GBIF


A estratégia de busca pelos registros é da mais ampla para a mais estrita (*top-down search*), e para isso precisaremos "garimpar" todos os nossos registros de interesse na "mina" de registros disponíveis. Para este tutorial, estaremos usando o repositório do [GBIF](https://www.gbif.org/).


Para esta primeira busca, vamos usar [esta database ](https://www.gbif.org/occurrence/download/0177086-210914110416597), que reúne 3.612 datasets e conta com 12.842.010 registros de coleções biológicas de todos os grupos seres vivos listados como ocorrendo no Brasil. Note que este conjunto de dados não inclui outras fontes de origem que não sejam materiais depositados nos herbários ou museus. 


**Observação 1**: Este arquivo é super pesado (3,9 GB compactado, e mais de 15 GB descompactado!) e pode demorar horas para baixar dependendo da velocidade da sua internet.


**Observação 2**: Uma vez baixado, JAMAIS tente abrir este arquivo, certamente vai travar o seu computador, ou o arquivo simplesmente não será aberto. Bases de dados grandes como estas só podem ser manipuladas via [SQL](https://en.wikipedia.org/wiki/SQL), faremos isso no próprio R mais adiante. 


### 2.2. Base de nomes da Flora do Brasil 2020


Para checar o estado taxonômico e nomenclatural dos nomes associados aos registros, vamos usar a base de dados da [Flora do Brasil 2020](http://floradobrasil.jbrj.gov.br/reflora/PrincipalUC/PrincipalUC.do;jsessionid=0D61E6157D3E362DFE01A5F66C4CB2D4). Para fazer o download desta base de dados, faça o que se segue:


1. Na página da Flora do Brasil 2020, clique na aba "Acesso aos Dados";


2. Clique em "Dados no formato Darwin Core Archive (Atualizado Semanalmente)". Você será redirecionado para a página do repositório de dados da Flora 2020 que contém os links para download da base de dados.

3. Clique em "DwC-A" nas opções de download. Um arquivo chamado `dwca-lista_especies_flora_brasil-v393.325.zip` deverá ser baixado.


A partir daqui, vamos trabalhar com a base de dados no próprio Excel, de modo a gerar um arquivo com formato e condições específicas, chamado `flora2020.txt`. Este arquivo também está disponível para download clicando aqui.

## 3. Abrindo os arquivos e carregando-os no R

Vamos agora ao R/RStudio e começar a abrir os arquivos. Primeiro, vamos carregar os pacotes (*libraries*) necessários para este tutorial.

Ah, não se esqueça de selecionar o seu diretório de trabalho (wd) através da função `setwd()`. Faça questão de criar uma pasta com um nome curto, e num diretório curto (evite pastas dentro de pastas), isso pode atrapalhar o seu trabalho.

```{r eval=FALSE, include=TRUE}

# Abrindo os pacotes...
library(sqldf)
library(taxize)
library(rgbif)
library(data.table)
library(dplyr)
library(stringr)
library(readxl)
library(openxlsx)

## Caso você não tenha os pacotes acima, certifique-se de instalá-los de antemão, através da função install.packages().

```


### 3.1. Restringindo o universo de busca da Flora 2020

Ao fazer o download da base de dados da Flora 2020, ela vem estruturada no padrão [Darwin Core (DwC)](https://www.gbif.org/pt/darwin-core), que oferece uma estrutura estável, direta e flexível para compilar dados de biodiversidade a partir de fontes variadas. Essencialmente, o formato DwC consiste em um arquivo compactado ("zipado") com nove ou dez arquivos de texto interconectados. Como não vamos precisar de todas as informações desses arquivos, convém integrar apenas as colunas de interesse em uma única tabela (ou arquivo) de antemão, para que possamos prosseguir com as checagens dos próximos passos.


Podemos fazer isso tanto no Excel, como no R. Para agilizar o tutorial, já preparei um arquivo com a planilha ajustada para análise, [clique aqui](https://github.com/collisilva/ucs_sp_tutorial/raw/main/fb2020.txt) para fazer o download. Em termos gerais, eu padronizei a tabela para incluir informações da origem da espécie (se ocorre no estado de São Paulo, se é endêmica do estado, e se a espécie é nativa, naturalizada ou cultivada), além de remover informações ambíguas, duvidosas e incompletas sobre alguns nomes.


Vamos incluir essa tabela no nosso ambiente de trabalho e chamar ela de `flora2020`. 


```{r eval=FALSE, include = T}
read.csv(choose.files()) -> flora2020 ##selecione o arquivo "fb2020.txt" que você baixou no seu diretório

```


## 4. Fazendo a busca em SQL do gazzetteer de interesse


Agora, faremos  uma *query* via SQL, e selecionar apenas aqueles registros da base de dados de ocorrência do GBIF que contenham a UC de interesse. Vamos primeiro trabalhar com uma busca simples, e buscar o gazzetteer "Serra do Mar", em menção ao Parque Estadual Serra do Mar. Note que outras buscas por outros topônimos devem ser feitas para recuperar mais registros.


A busca pode demorar entre 20 e 60 minutos...

```{r eval=FALSE, include = TRUE}
start_time <- Sys.time() #para termos noção de quanto tempo levou o processo

selected <- read.csv.sql(choose.files(), sep = '\t', eol = '\n',
             sql = 'SELECT * FROM file WHERE locality LIKE "%Serra do Mar%"') # Note que aqui está "%Serra do Mar%", mas o gazzetteer poderia ser outro!!!

end_time <- Sys.time()
end_time - start_time

## Em "choose.files()", selecione o arquivo "occurrence.txt" da pasta que você baixou do GBIF - é o arquivo mais pesado da pasta que contém todas as informações das ocorrências obtidas na busca.
```

Após a busca, vamos exportar os resultados dessa seleção de registros que potencialmente estão na área de interesse: 

```{r eval=FALSE, include = TRUE}
write.table(selected, "PESM_registros_raw.txt", sep = '\t', row.names = F)
```


## 5. Checando e corrigindo o estado dos nomes usando a base da Flora do Brasil 2020

Com a busca feita, podemos proceder para a checagem dos nomes usando a base de dados da Flora 2020. 

```{r eval=F, include = T}

### Estes passos são para recuperar o taxonKey do registro, que corresponde ao nome científico determinado no registro. Esta é a informação que vai ser cruzada com a base de nomes da Flora 2020.

selected$taxonKey -> taxkey_search_r
as.data.frame(taxkey_search_r) -> taxkey_search_r
selected$gbifID -> taxkey_search_r[,2]
taxkey_search_r$name_fetch <- ""
colnames(taxkey_search_r) <- c("taxonKey", "gbifID", "name_fetch")
start_time <- Sys.time()
for (i in 1:nrow(selected)){
  name_usage(key = taxkey_search_r[i,1]) -> res
  res[["data"]] -> res
  res$canonicalName -> out
  out -> taxkey_search_r[i,3]
}

end_time <- Sys.time()
end_time - start_time

###Os passos a seguir agora vão fazer o cruzamento das informações GBIF-Flora 2020...

merge(flora2020, taxkey_search_r, by.y = "name_fetch", by.x = "name_concat", all.y = T) -> taxkey_search
merge(taxkey_search, selected, by.x = "gbifID", by.y = "gbifID") -> data_merged
data_merged <- data_merged[!(is.na(data_merged$id)),]

```


Note que o formato DwC do GBIF contém centenas de colunas, e não precisaremos de informações de muitas delas. Vamos apenas então selecionar as colunas que de fato serão interessantes para os nossos objetivos de filtragem:


```{r eval = F, include = T}


export <- data.frame("", data_merged$higherClassification.x, data_merged$family.x, data_merged$taxonRank.x,
                     data_merged$UseName, data_merged$establishmentMeans.x, data_merged$iucnRedListCategory,
                     data_merged$identifier,data_merged$catalogNumber, data_merged$collectionCode,
                     data_merged$gbifID,data_merged$recordedBy, data_merged$recordNumber, data_merged$year,
                     data_merged$month,data_merged$day,data_merged$identifiedBy, data_merged$stateProvince,
                     data_merged$municipality,data_merged$locality, data_merged$decimalLatitude,
                     data_merged$decimalLongitude, data_merged$occurrence_SP, data_merged$endemica_SP)


#O passo a seguir vai selecionar APENAS os registros determinados a nível de ESPÉCIE. Caso você queira dar uma olhada nos registros indet, você deve voltar ao arquivo `_raw` que você exportou há alguns passos acima, após a busca via SQL.

export %>% filter(data_merged.taxonRank.x == "ESPECIE") -> export


#Agora, vamos nomear o nome das colunas selecionadas para algo mais compreensível na planilha para fazer a análise...

colnames(export) <- c("Observações", "Grupos", "Famílias", "Taxon Rank", "Espécies",
                      "Origem", "Categoria de Ameaça IUCN",
                      "Identificador", "CatalogNumber", "Herbário", "GBIF ID", "Coletor", "No. coleta",
                      "Ano de coleta", "Mês", "Dia", "Determinador", "Estado", "Município",
                      "Localidade", "Latitude", "Longitude", "Ocorre em SP segundo Flora 2020?", "Endêmica de SP segundo Flora 2020?")

```

## 6. Sinalizando algumas inconsistências e exportando a planilha final

Agora que temos a base de dados corrigida para os nomes, e potencialmente com os registros que queremos para o lugar que queremos, podemos começar a explorar melhor os registros. Certamente ainda há registros que não ocorrem no PESM, mas por alguma razão possuem "Serra do Mar" na localização (*e.g.* o registro pode ocorrer na Serra do Mar, mas não dentro dos limites do Parque, ou a espécie não ocorre no estado de SP segundo a Flora 2020 e a determinação está potencialmente errada (ou é um registro novo para o estado)). Além disso, há muitos casos onde um registro possui mais de uma determinação, como casos onde diferentes duplicatas possuem diferentes determinações, ou casos onde por alguma razão a checagem de nomes pelos sinônimos falhou. Nesses casos, é possível sinalizar essas inconsistências, para que os registros sejam manualmente avaliados.


1. Se há duplicatas com duas ou mais determinações distintas, ou algum problema com o nome que deve ser avaliado;
2. Se o registro corresponde a uma espécie com ocorrência conhecida para o estado de São Paulo; caso contrário, deve-se avaliar se a determinação está errada, ou se se trata de um registro novo da espécie para o estado.



```{r eval = F, include = T}


for (i in 1:nrow(merged_export)){
  sum(merged_export$Espécies == merged_export$Espécies[i]) -> merged_export$cont.spp[i]
  sum(merged_export$concat.code == merged_export$concat.code[i]) -> merged_export$cont.id[i]
  if (merged_export$Herbário[i] == "SPSF"){
    merged_export$`Código de Barra`[i] <- paste(merged_export$Herbário[i], merged_export$CatalogNumber[i], sep = "") 
    merged_export$Observações[i] <- "COLETA DO SPSF, INCLUIR QUANDO DIGITALIZAR"
    merged_export$`BARCODE ELEGIDO`[i] <- paste(merged_export$Herbário[i], merged_export$CatalogNumber[i], sep = "")
  }
  if (as.integer(merged_export$cont.id[i]) > as.integer(merged_export$cont.spp[i]) & as.integer(merged_export$`No. coleta`[i]) != 0){
    merged_export$Observações[i] <- "DUPLICATAS COM DUAS OU MAIS DETERMINAÇÕES DISTINTAS, OU COM ALGUM PROBLEMA NO NOME, CHECAR QUAL ID CORRETA"
  }
  if (merged_export$`Ocorre em SP segundo Flora 2020?`[i] == 0) {
    merged_export$Observações[i] <- "CHECAR, ESPÉCIE NÃO OCORRE NO ESTADO DE SÃO PAULO SEGUNDO A FLORA 2020"
    
  }
  
}
```



Vamos, ainda, fazer mais uma camada de checagem: vamos sinalizar se há espécies (e, se houver, quais são) listadas como ameaçadas de extinção segundo lista da IUCN, mas que a última coleta foi feita antes de 1970. Estas espécies podem ser consideradas "prioritárias para conservação" (note criação de nova coluna no objeto `merged_export`, chamada `Prioritarias_conservacao`), ou talvez "alvos" para que possamos ir a campo no PESM para, com sorte, reencontrá-las:


```{r eval = F, include = T}

merged_export$Prioritarias_conservacao <- ""
for (i in 1:nrow(merged_export)){
  if (merged_export$`Ano de coleta`[i] < 1970 & merged_export$cont.spp == 1 & 
      (merged_export$`Categoria de Ameaça IUCN`[i] == "CR" |
      merged_export$`Categoria de Ameaça IUCN`[i] == "DD" |
      merged_export$`Categoria de Ameaça IUCN`[i] == "VU" |
      merged_export$`Categoria de Ameaça IUCN`[i] == "EN"))
    {
    merged_export$Prioritarias_conservacao <- "ESPÉCIE PRIORITÁRIA PARA CONSERVAÇÃO - APENAS 1 COLETA, ANTES DE 1970, E AMEAÇADA DE EXTINÇÃO SEGUNDO IUCN"
  }
}

```


Finalmente, podemos exportar a tabela com todos os resultados em formato txt, e depois podemos seguir o nosso trabalho importando este arquivo no Excel ou em outro programa de edição de planilhas.

```{r eval = F, include = T}
write.table(merged_export, "PESM_registros_filtrados.txt", sep = "\t", row.names = F)
```

O processo de checagem de inconsistências pode ser exaustivo, e pode conter muitas outras camadas, ou filtros que podem ser avaliadas no processo de curadoria dos dados.

